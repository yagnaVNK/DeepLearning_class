{"cells":[{"cell_type":"markdown","metadata":{"id":"aXkszegKMMMn"},"source":["# Chapter 3 - Deep Learning Development with PyTorch "]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3836,"status":"ok","timestamp":1614452126103,"user":{"displayName":"Joe Papa","photoUrl":"","userId":"00487850786587503652"},"user_tz":300},"id":"gmdHVgDurviK","outputId":"634d719e-1132-437d-aa17-09e7140e20d6"},"outputs":[],"source":["import torch\n","import torchvision\n","from torchvision.datasets import CIFAR10"]},{"cell_type":"markdown","metadata":{"id":"n-BCIj1oG_sA"},"source":["## Data Transforms"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1148,"status":"ok","timestamp":1614452150871,"user":{"displayName":"Joe Papa","photoUrl":"","userId":"00487850786587503652"},"user_tz":300},"id":"rgMYPb-DLP3i","outputId":"08c74024-6775-4d17-837b-041f8145438b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n"]}],"source":["from torchvision import transforms\n","\n","train_transforms = transforms.Compose([\n","  transforms.RandomCrop(32, padding=4),\n","  transforms.RandomHorizontalFlip(),\n","  transforms.ToTensor(),\n","  transforms.Normalize(\n","      (0.4914, 0.4822, 0.4465),\n","      (0.2023, 0.1994, 0.2010))])\n","\n","train_data_transforms = CIFAR10(root=\"./train/\",\n","                    train=True, \n","                    download=True,\n","                    transform=train_transforms)"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":665,"status":"ok","timestamp":1614452156310,"user":{"displayName":"Joe Papa","photoUrl":"","userId":"00487850786587503652"},"user_tz":300},"id":"eIMW68MlET2J","outputId":"859506f4-c5c8-4c1c-ac87-34d9c4c28f89"},"outputs":[],"source":["test_transforms = transforms.Compose([\n","  transforms.ToTensor(),\n","  transforms.Normalize(\n","      (0.4914, 0.4822, 0.4465),\n","      (0.2023, 0.1994, 0.2010))])\n","\n","test_data_transforms = torchvision.datasets.CIFAR10(\n","      root=\"./test/\", \n","      train=False, \n","      transform=test_transforms)\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["targets = [1, 3, 5, 9]\n","\n","indices = [i for i, label in enumerate(train_data_transforms.targets) if label in targets]\n","\n","from torch.utils.data.dataset import Subset\n","\n","train_subset = Subset(train_data_transforms, indices)"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["targets = [1, 3, 5, 9]\n","\n","indices = [i for i, label in enumerate(test_data_transforms.targets) if label in targets]\n","\n","from torch.utils.data.dataset import Subset\n","\n","test_subset = Subset(test_data_transforms, indices)"]},{"cell_type":"markdown","metadata":{"id":"6W21V3InIG50"},"source":["## Data Batching"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"FXYBiTpjHr0N"},"outputs":[],"source":["trainloader = torch.utils.data.DataLoader(\n","                    train_subset, \n","                    batch_size=16, \n","                    shuffle=True)"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":340,"status":"ok","timestamp":1614452162062,"user":{"displayName":"Joe Papa","photoUrl":"","userId":"00487850786587503652"},"user_tz":300},"id":"-PZ-qrHmg4xG","outputId":"112556a5-368a-4560-f827-d8c088d95879"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([16, 3, 32, 32])\n","torch.Size([16])\n"]}],"source":["data_batch, labels_batch = next(iter(trainloader))\n","print(data_batch.size())\n","\n","print(labels_batch.size())"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"BwY6m10IThoG"},"outputs":[],"source":["testloader = torch.utils.data.DataLoader(\n","                    test_subset, \n","                    batch_size=16, \n","                    shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"VKrUoF3MIp2i"},"source":["## Model Design\n","\n"]},{"cell_type":"markdown","metadata":{"id":"m_1AMyp5phja"},"source":["### Using Existing & Pre-trained models"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["1e3ac1e7ed9f4e259135ab348fff5b80","ab25a08ae2ac4d1f94ea946926a73ac4","173c84071d6e4c10826d449493811468","2634472c0b9f4cf1b06fff7911be1978","b1ae174706d344978ced2df4995b52fa","f033eae71da045ea97603919371aaab0","d03cf801ec48411c8be10b55b2a84657","b1c80cb38cd94512ba5b459f3b62ace0"]},"executionInfo":{"elapsed":4290,"status":"ok","timestamp":1614452170897,"user":{"displayName":"Joe Papa","photoUrl":"","userId":"00487850786587503652"},"user_tz":300},"id":"eLqiKEcf2d7R","outputId":"952c5231-6aea-4cf8-a973-3cfb40a5c879"},"outputs":[],"source":["from torchvision import models\n","\n","vgg16 = models.vgg16(pretrained=True)"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1614452172007,"user":{"displayName":"Joe Papa","photoUrl":"","userId":"00487850786587503652"},"user_tz":300},"id":"0dBa8c5E8bmt","outputId":"222e1375-706c-4b71-a693-5ae2191c20a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sequential(\n","  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): ReLU(inplace=True)\n","  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (3): ReLU(inplace=True)\n","  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (6): ReLU(inplace=True)\n","  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (8): ReLU(inplace=True)\n","  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (11): ReLU(inplace=True)\n","  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (13): ReLU(inplace=True)\n","  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (15): ReLU(inplace=True)\n","  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (18): ReLU(inplace=True)\n","  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (20): ReLU(inplace=True)\n","  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (22): ReLU(inplace=True)\n","  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (25): ReLU(inplace=True)\n","  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (27): ReLU(inplace=True)\n","  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (29): ReLU(inplace=True)\n","  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",")\n","AdaptiveAvgPool2d(output_size=(7, 7))\n","Sequential(\n","  (0): Linear(in_features=25088, out_features=4096, bias=True)\n","  (1): ReLU(inplace=True)\n","  (2): Dropout(p=0.5, inplace=False)\n","  (3): Linear(in_features=4096, out_features=4096, bias=True)\n","  (4): ReLU(inplace=True)\n","  (5): Dropout(p=0.5, inplace=False)\n","  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",")\n"]}],"source":["print(vgg16.features)\n","\n","print(vgg16.avgpool)\n","\n","print(vgg16.classifier)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sequential(\n","  (0): Linear(in_features=25088, out_features=4096, bias=True)\n","  (1): ReLU(inplace=True)\n","  (2): Dropout(p=0.5, inplace=False)\n","  (3): Linear(in_features=4096, out_features=4096, bias=True)\n","  (4): ReLU(inplace=True)\n","  (5): Dropout(p=0.5, inplace=False)\n","  (6): Linear(in_features=4096, out_features=4, bias=True)\n",")\n"]},{"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32mc:\\Users\\kaasa\\Documents\\GitHub\\DeepLearning_class\\Assignment 3\\Problem2.ipynb Cell 16\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kaasa/Documents/GitHub/DeepLearning_class/Assignment%203/Problem2.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(vgg16\u001b[39m.\u001b[39mclassifier)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kaasa/Documents/GitHub/DeepLearning_class/Assignment%203/Problem2.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m device \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kaasa/Documents/GitHub/DeepLearning_class/Assignment%203/Problem2.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m vgg_model \u001b[39m=\u001b[39m vgg16\u001b[39m.\u001b[39;49mto(device \u001b[39m=\u001b[39;49m device)\n","File \u001b[1;32mc:\\Users\\kaasa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1158\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1160\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n","File \u001b[1;32mc:\\Users\\kaasa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\kaasa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\kaasa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 833\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    834\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    835\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n","File \u001b[1;32mc:\\Users\\kaasa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m   1156\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1158\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n","\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"]}],"source":["import torch.nn as nn\n","vgg16.classifier[-1] = nn.Linear(4096,4)\n","\n","print(vgg16.classifier)\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","vgg_model = vgg16.to(device = device)"]},{"cell_type":"markdown","metadata":{"id":"Pl7yIw-uY-RM"},"source":["## The PyTorch NN Module (torch.nn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hWKdV4PMnL06"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class SimpleNet(nn.Module):\n","\n","    def __init__(self):\n","        super(SimpleNet, self).__init__()\n","        self.fc1 = nn.Linear(2048, 256)\n","        self.fc2 = nn.Linear(256, 64)\n","        self.fc3 = nn.Linear(64,2)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 2048)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = F.softmax(self.fc3(x),dim=1)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":497,"status":"ok","timestamp":1614452183819,"user":{"displayName":"Joe Papa","photoUrl":"","userId":"00487850786587503652"},"user_tz":300},"id":"RkAy9PmTpFkj","outputId":"3c4c27d1-6cba-4101-d600-aaafa70eb5b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["SimpleNet(\n","  (fc1): Linear(in_features=2048, out_features=256, bias=True)\n","  (fc2): Linear(in_features=256, out_features=64, bias=True)\n","  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",")\n"]}],"source":["simplenet = SimpleNet()\n","print(simplenet)\n","\n","input = torch.rand(2048)\n","output = simplenet(input)"]},{"cell_type":"markdown","metadata":{"id":"LurpNmIpnpLo"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"trFZ1GftyRqj"},"outputs":[],"source":["from torch import nn\n","import torch.nn.functional as F\n","\n","class LeNet5(nn.Module):\n","    def __init__(self):\n","        super(LeNet5, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5) # <1>\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n","        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n","        x = x.view(-1, int(x.nelement() / x.shape[0]))\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","LeNet_model = LeNet5().to(device=device)"]},{"cell_type":"markdown","metadata":{"id":"2d2FZ-sJqI4F"},"source":["### Fundamental Training Loop"]},{"cell_type":"markdown","metadata":{"id":"_6yMHCA4sRUB"},"source":["Code Annotations:\n","\n","<1> Our training loop\n","\n","<2> Need to move inputs and labels to GPU is avail.\n","\n","<3> Zero out gradients before each backprop or they'll accumulate\n","\n","<4> Forward pass\n","\n","<5> Compute loss\n","\n","<6> Backpropagation, compute gradients\n","\n","<7> Adjust parameters based on gradients\n","\n","<8> accumulate batch loss so we can average over epoch\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iEOGrjvNeNAN"},"outputs":[],"source":["from torch import optim\n","from torch import nn\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(vgg_model.parameters(), # <1>\n","                      lr=0.001, \n","                      momentum=0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":238908,"status":"ok","timestamp":1614452438846,"user":{"displayName":"Joe Papa","photoUrl":"","userId":"00487850786587503652"},"user_tz":300},"id":"MbnVGZAqyx4Z","outputId":"920014b6-7298-4a1b-c394-6c793fbd086d"},"outputs":[{"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32mc:\\Users\\kaasa\\Documents\\GitHub\\DeepLearning_class\\Assignment 3\\Problem2.ipynb Cell 25\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kaasa/Documents/GitHub/DeepLearning_class/Assignment%203/Problem2.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m epoch_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kaasa/Documents/GitHub/DeepLearning_class/Assignment%203/Problem2.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m trainloader:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kaasa/Documents/GitHub/DeepLearning_class/Assignment%203/Problem2.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39;49mto(device) \u001b[39m# <2>\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kaasa/Documents/GitHub/DeepLearning_class/Assignment%203/Problem2.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kaasa/Documents/GitHub/DeepLearning_class/Assignment%203/Problem2.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad() \u001b[39m# <3>\u001b[39;00m\n","\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"]}],"source":["N_EPOCHS = 10 \n","for epoch in range(N_EPOCHS): # <1>\n","\n","    epoch_loss = 0.0\n","    for inputs, labels in trainloader:\n","        inputs = inputs.to(device) # <2>\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad() # <3>\n","\n","        outputs = vgg_model(inputs) # <4>\n","        loss = criterion(outputs, labels) # <5>\n","        loss.backward() # <6>\n","        optimizer.step() # <7>\n","\n","        epoch_loss += loss.item() # <8>\n","    print(\"Epoch: {} Loss: {}\".format(epoch, \n","                  epoch_loss/len(trainloader)))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["625 16\n","Test Accuracy: 0.8989999890327454\n"]}],"source":["num_correct = 0.0\n","\n","for x_test_batch, y_test_batch in testloader:\n","\n","    vgg_model.eval()\n","\n","    y_test_batch = y_test_batch.to(device)\n","\n","    x_test_batch = x_test_batch.to(device)\n","\n","    y_pred_batch = vgg_model(x_test_batch)\n","\n","    _, predicted = torch.max(y_pred_batch, 1)\n","\n","    num_correct += (predicted == y_test_batch).float().sum()\n","\n"," \n","\n","accuracy = num_correct/(len(testloader)*testloader.batch_size)\n","\n"," \n","\n","print(len(testloader), testloader.batch_size)\n","\n","print(\"Test Accuracy: {}\".format(accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch import nn\n","import torch.nn.functional as F\n","\n","class LeNet5(nn.Module):\n","    def __init__(self):\n","        super(LeNet5, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 6, 5) # <1>\n","        self.conv2 = nn.Conv2d(6, 16, 5)\n","        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, 10)\n","\n","    def forward(self, x):\n","        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n","        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n","        x = x.view(-1, int(x.nelement() / x.shape[0]))\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","LeNet_model = LeNet5().to(device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch import optim\n","from torch import nn\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(LeNet_model.parameters(), # <1>\n","                      lr=0.001, \n","                      momentum=0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0 Loss: 1.967775545425415\n","Epoch: 1 Loss: 1.6096732638931275\n","Epoch: 2 Loss: 1.4850714733695984\n","Epoch: 3 Loss: 1.3929108724975585\n","Epoch: 4 Loss: 1.3269605978775025\n","Epoch: 5 Loss: 1.2712818297195434\n","Epoch: 6 Loss: 1.2367817444992066\n","Epoch: 7 Loss: 1.2026917700767517\n","Epoch: 8 Loss: 1.1773305163288117\n","Epoch: 9 Loss: 1.1587271730613709\n"]}],"source":["N_EPOCHS = 10 \n","for epoch in range(N_EPOCHS): # <1>\n","\n","    epoch_loss = 0.0\n","    for inputs, labels in trainloader:\n","        inputs = inputs.to(device) # <2>\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad() # <3>\n","\n","        outputs = LeNet_model(inputs) # <4>\n","        loss = criterion(outputs, labels) # <5>\n","        loss.backward() # <6>\n","        optimizer.step() # <7>\n","\n","        epoch_loss += loss.item() # <8>\n","    print(\"Epoch: {} Loss: {}\".format(epoch, \n","                  epoch_loss/len(trainloader)))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["625 16\n","Test Accuracy: 0.6245999932289124\n"]}],"source":["num_correct = 0.0\n","\n","for x_test_batch, y_test_batch in testloader:\n","\n","    LeNet_model.eval()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","    y_test_batch = y_test_batch.to(device)\n","\n","    x_test_batch = x_test_batch.to(device)\n","\n","    y_pred_batch = LeNet_model(x_test_batch)\n","\n","    _, predicted = torch.max(y_pred_batch, 1)\n","\n","    num_correct += (predicted == y_test_batch).float().sum()\n","\n"," \n","\n","accuracy = num_correct/(len(testloader)*testloader.batch_size)\n","\n"," \n","\n","print(len(testloader), testloader.batch_size)\n","\n","print(\"Test Accuracy: {}\".format(accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["LeNet5(\n","  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n","  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","  (fc1): Linear(in_features=400, out_features=120, bias=True)\n","  (fc2): Linear(in_features=120, out_features=84, bias=True)\n","  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",")\n","VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=10, bias=True)\n","  )\n",")\n"]}],"source":["print(LeNet_model)\n","print(vgg_model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPQzmPMCU0PPecrFAHhYwC+","collapsed_sections":[],"name":"03_Deep_Learning_Development_with_PyTorch.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"173c84071d6e4c10826d449493811468":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_f033eae71da045ea97603919371aaab0","max":553433881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b1ae174706d344978ced2df4995b52fa","value":553433881}},"1e3ac1e7ed9f4e259135ab348fff5b80":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_173c84071d6e4c10826d449493811468","IPY_MODEL_2634472c0b9f4cf1b06fff7911be1978"],"layout":"IPY_MODEL_ab25a08ae2ac4d1f94ea946926a73ac4"}},"2634472c0b9f4cf1b06fff7911be1978":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1c80cb38cd94512ba5b459f3b62ace0","placeholder":"​","style":"IPY_MODEL_d03cf801ec48411c8be10b55b2a84657","value":" 528M/528M [00:02&lt;00:00, 214MB/s]"}},"2c13c5856fac429eadf46ffca57dc785":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b0dc26f1d4cb404db5e6e2b1a95ea2de","IPY_MODEL_6809253c5bd54680b2968835f7947bb5"],"layout":"IPY_MODEL_c38a785ca7b746739c13b29dd9a3171e"}},"2e8e1a3fc2604b499ed1ab5b593d6044":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3643244f66014d98a9c1f2b377ef28c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1706660b23e45dc92710036e0e324b5","placeholder":"​","style":"IPY_MODEL_2e8e1a3fc2604b499ed1ab5b593d6044","value":" 170500096/? [00:16&lt;00:00, 52970784.72it/s]"}},"3fbc8d76caf34f029a2ab899f884f21a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fa154f68f37486fa4e1269c8a192f2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6809253c5bd54680b2968835f7947bb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9b979f29470494d8e58fa74281fa6d8","placeholder":"​","style":"IPY_MODEL_ce8684f2708b44a781fbcbe932bd36e4","value":" 170500096/? [00:20&lt;00:00, 55977091.72it/s]"}},"730050982b27418394fc819c91db79d2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"816896dd6c9b490db10edeb04edfaa8f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fbc8d76caf34f029a2ab899f884f21a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_730050982b27418394fc819c91db79d2","value":1}},"a9b979f29470494d8e58fa74281fa6d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab25a08ae2ac4d1f94ea946926a73ac4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0dc26f1d4cb404db5e6e2b1a95ea2de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_5fa154f68f37486fa4e1269c8a192f2f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fa33932b86e149978b2520732e38be4a","value":1}},"b1706660b23e45dc92710036e0e324b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1ae174706d344978ced2df4995b52fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"b1c80cb38cd94512ba5b459f3b62ace0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c35a5390aae647b8b6a6a57642257417":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_816896dd6c9b490db10edeb04edfaa8f","IPY_MODEL_3643244f66014d98a9c1f2b377ef28c7"],"layout":"IPY_MODEL_d7c72262592d45bfa5ed31e630ca8a42"}},"c38a785ca7b746739c13b29dd9a3171e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce8684f2708b44a781fbcbe932bd36e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d03cf801ec48411c8be10b55b2a84657":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7c72262592d45bfa5ed31e630ca8a42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f033eae71da045ea97603919371aaab0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa33932b86e149978b2520732e38be4a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}}}}},"nbformat":4,"nbformat_minor":0}
